1) Historia robotyki - ważne fakty mające wpływ na rozwój robotyki inteligentnej, 
Robotyka, zaczynając od pradawnych korzeni z Mechanizmem Antykyteryjskim, przeszła fascynujący rozwój. Wraz z pojawieniem się pierwszych robotów przemysłowych w latach 50. XX wieku, świat świadkował rewolucji w automatyzacji produkcji. Koncepcja sztucznej inteligencji, zainicjowana w tym samym okresie, otworzyła nowe horyzonty dla robotów, sugerując możliwość samodzielnego myślenia. Jednak to dopiero w latach 90., dzięki algorytmom uczenia maszynowego, roboty zyskały zdolność do adaptacji i samodzielnego uczenia się, co zrewolucjonizowało obszar robotyki inteligentnej. Obecnie, w erze powszechnego wykorzystania sztucznej inteligencji, robotyka rozwija się dynamicznie, zmieniając sposób, w jaki ludzie współpracują z maszynam

2) Test Turinga i jego kontr przykład – Chiński pokój, Czy test Turinga jest aktualny? 
Test Turinga:
Alan Turing zaproponował test, aby ocenić zdolność maszyn do wykonywania inteligentnych działań na poziomie człowieka. Według testu, jeśli maszyna może przekonać człowieka, że jest również człowiekiem podczas rozmowy, to można uznać ją za sztuczną inteligencję.
Chiński pokój:
Chiński pokój to koncepcja stworzona w kontekście krytyki Testu Turinga. W scenariuszu Chińskiego pokoju, osoba znajdująca się w pokoju otrzymuje pytania w języku chińskim, a za pomocą instrukcji i odpowiedzi na te pytania udaje, że zna chiński, chociaż tak naprawdę nie rozumie tego języka. Analogicznie, argumentuje się, że maszyna wykonująca pewne zadania nie musi rozumieć ich sensu, tak jak osoba w Chińskim pokoju nie rozumie chińskiego.
Aktualność Testu Turinga:
Test Turinga jest kontrowersyjny i wielu uważa, że nie jest wystarczający do oceny prawdziwej sztucznej inteligencji. Współczesne podejścia do sztucznej inteligencji skupiają się na bardziej złożonych aspektach, takich jak uczenie maszynowe, rozumienie kontekstu i tworzenie algorytmów zdolnych do samodzielnego myślenia. W związku z tym, niektórzy uważają, że Test Turinga jest przestarzały i nie odzwierciedla w pełni nowoczesnych wyzwań i możliwości w dziedzinie sztucznej inteligencji.

3) Słaba AI vs Silna AI (czym się różnią?; który wariant wystarczy do dorównania człowiekowi)? 
Słaba sztuczna inteligencja (ASi) koncentruje się na jednym zadaniu, nie przekraczając swojej specyficznej dziedziny zastosowań. Przykłady słabej AI obejmują systemy do rozpoznawania mowy, rekomendacyjne algorytmy zakupowe czy sztuczne inteligencje używane w grach komputerowych. Słaba AI nie posiada zdolności ogólnego zrozumienia kontekstu ani samodzielnego myślenia, działając jedynie w ramach ściśle określonych parametrów. W odróżnieniu od tego, silna sztuczna inteligencja posiada zdolność ogólnego rozumienia, umożliwiając jej operowanie w różnych dziedzinach i przyswajanie nowej wiedzy. Silna AI może rozumieć kontekst, podejmować decyzje i działać na poziomie zbliżonym do ludzkiej inteligencji. Różnice między nimi polegają na zakresie zastosowań i zdolnościach rozumieniowych.

4) Prawa robotyki Asimova, 
1.Robot nie może zranić człowieka ani przez zaniechanie działania dopuścić do jego nieszczęścia.
2.Robot musi być posłuszny człowiekowi, chyba że stoi to w sprzeczności z Pierwszym Prawem.
3.Robot musi dbać o siebie, o ile tylko nie stoi to w sprzeczności z Pierwszym lub Drugim Prawem.

5) Prawa robotyki w praktyce, 
Koreański rząd obecnie pracuje nad stworzeniem dokumentu regulującego prawa robotów. Również w Wielkiej Brytanii Sir David King, główny doradca naukowy rządu Jej Królewskiej Mości uważa, że gdy w przyszłości zostaną stworzone czujące roboty należy dać im te same prawa co ludziom. Opinia taka została wyrażona w dokumencie przygotowanym przez firmę konsultująca Outsights oraz zajmującą się badaniami opinii publicznej Ipsos Mori. Dokument dotyczy Wielkiej Brytanii w roku 2056, a jego autorzy stwierdzili, że do tego czasu roboty posiadające uczucia mogą być czymś powszechnym. W dokumencie czytamy, że jeśli kiedyś rzeczywiście powstanie SI, trzeba będzie przyznać wyposażonym w nią urządzeniom takie prawa i obowiązki jak ludziom. Roboty miałyby więc prawa wyborcze, płaciłyby podatki i służyły w wojsku. Jeśli przyznamy robotom wyposażonym w sztuczną inteligencję pełnię praw, to państwa będą zobowiązane do zapewnienia im wszelkich korzyści wynikających z przynależności do społeczeństwa, a więc prawa do pracy, zamieszkania oraz prawa do opieki zdrowotnej polegającej na ich naprawie

6) Techniki lokalizacji (odnajdowania pozycji robota na mapie):
a) filtr histogramowy,
b) filtr partykułowy,
c) lokalizacja za pomocą znaczników mapy.
a) Filtr histogramowy: Jest to technika lokalizacji wykorzystująca statystyczne podejście do odnajdywania pozycji robota. Filtr histogramowy utrzymuje rozkład prawdopodobieństwa pozycji robota na podstawie wcześniejszych pomiarów i sterowań. Aktualizuje się zgodnie z nowymi danymi sensorycznymi, co umożliwia coraz dokładniejsze określanie lokalizacji.
b) Filtr partykułowy: To inna metoda probabilistyczna lokalizacji, która reprezentuje pozycję robota za pomocą zbioru "partykułów" (próbek). Każdy z tych partykułów reprezentuje potencjalną pozycję robota. W miarę przemieszczania się robota i aktualizacji danych sensorycznych, waga każdego partykułu jest dostosowywana, aby odzwierciedlała prawdopodobieństwo, że dany partykuł odpowiada rzeczywistej pozycji robota.
c) Lokalizacja za pomocą znaczników mapy: Ta technika polega na identyfikacji i śledzeniu znaczników umieszczonych w otoczeniu robota. Znaczniki to charakterystyczne punkty odniesienia, takie jak kody kreskowe, QR-kody lub inne unikalne wzory. System wizyjny lub inne sensory są używane do rozpoznawania tych znaczników, co umożliwia precyzyjne określenie pozycji robota na podstawie ich względnych lokalizacji na mapie.

7) Planowanie trasy robotów mobilnych:
a) BUG I,
b) BUG II,
c) Tangent BUG.
d) A* w grafie,
e) A* w drzewie,
f) A* w siatce kwadratów pól (gridzie),
g) Technika generowania uniwersalnej polityki ruchu,
h) Przykład, w którym BUG I generuje krótszą trasę niż BUG II. 
a) BUG I: Algorytm planowania trasy, który zakłada, że robot przemieszcza się do przeszkody, a następnie porusza się wzdłuż niej, starając się znaleźć linię, która umożliwi mu osiągnięcie celu.
b) BUG II: Podobny do BUG I, jednak bardziej zaawansowany. Po osiągnięciu przeszkody, BUG II stara się znaleźć najkrótszą ścieżkę wzdłuż przeszkody, która umożliwi mu dojście do celu.
c) Tangent BUG: To ulepszona wersja BUG II, która minimalizuje ilość zawracania przy przeszkodach, starając się utrzymać styczność z nimi.
d) A w grafie:* Algorytm oparty na przeszukiwaniu grafu, używający heurystyki do szacowania kosztu podróży od punktu początkowego do celu. Jest to efektywna metoda planowania trasy w skomplikowanych przestrzeniach.
e) A w drzewie:* Podobny do A* w grafie, ale operuje na strukturze drzewa zamiast pełnego grafu.
f) A w siatce kwadratów pól (gridzie):* Przestrzeń jest podzielona na siatkę kwadratów, a algorytm A* jest stosowany do znajdowania najkrótszej ścieżki między polami.
g) Technika generowania uniwersalnej polityki ruchu: Wykorzystuje techniki uczenia maszynowego do generowania polityki ruchu, umożliwiającej robotowi podejmowanie decyzji dotyczących trasy w czasie rzeczywistym na podstawie obserwacji środowiska.
h) Przykład, w którym BUG I generuje krótszą trasę niż BUG II: Sytuacja, w której BUG I może osiągnąć cel bez konieczności zastosowania skomplikowanej trasy wzdłuż przeszkody, co skutkuje krótszą trasą w porównaniu do BUG II, który próbuje znaleźć najkrótszą ścieżkę wzdłuż przeszkody.

8) Kontrolery:
a) P - kontroler,
b) PD – kontroler,
c) PID – kontroler.
d) Sposób zastosowania kontrolerów w robocie typu 2WD (2 silniki zasilające koła i
podparcie).
a) P - kontroler: Kontroler proporcjonalny. Reguluje wyjście proporcjonalnie do różnicy między wartością zadaną a aktualną wartością.
b) PD - kontroler: Kontroler proporcjonalno-różniczkujący. Oprócz składnika proporcjonalnego uwzględnia również składnik różniczkujący, co pomaga w redukcji oscylacji i szybszej stabilizacji systemu.
c) PID - kontroler: Kontroler proporcjonalno-różniczkująco-całkujący. Obejmuje składniki proporcjonalny, różniczkujący i całkujący. Jest to rozwinięcie PD-kontrolera o zdolność do eliminacji błędów systematycznych.
d) Sposób zastosowania kontrolerów w robocie typu 2WD (2 silniki zasilające koła i podparcie):
P - kontroler: Stosowany do regulacji prędkości obrotowej kół w oparciu o różnicę między zadaną a rzeczywistą prędkością obrotową. Kontroluje prędkość każdego koła proporcjonalnie do błędu.
PD - kontroler: Dodatkowo do proporcjonalności, uwzględnia różniczkowanie, co pozwala na lepszą reakcję na dynamiczne zmiany w prędkości obrotowej kół.
PID - kontroler: Oprócz proporcjonalności i różniczkowania, dodaje składnik całkujący, co pozwala na eliminację błędów systematycznych i zapewnia lepszą stabilność systemu przy dłuższych działaniach.

9) Algorytm wygładzania ścieżki (Path smoothing) na bazie zejścia gradientowego. 
Algorytm wygładzania ścieżki na bazie zejścia gradientowego to metoda optymalizacji ścieżki, która polega na dostosowywaniu punktów trasy, aby zminimalizować krzywiznę i uczynić ścieżkę bardziej płynną. Poniżej przedstawiam ogólny opis algorytmu:
Inicjalizacja: Zaczynamy od pewnej drogi, którą chcemy wygładzić. Ta droga jest zazwyczaj reprezentowana przez serię punktów.
Funkcja celu: Definiujemy funkcję celu, która będzie minimalizować krzywiznę ścieżki. Często używa się kwadratu krzywizny (kwadratu odchylenia od prostej) jako funkcji celu.
Gradient: Obliczamy gradient funkcji celu względem pozycji każdego punktu na ścieżce. Gradient wskazuje kierunek najszybszego wzrostu funkcji celu.
Aktualizacja punktów: Korzystając z gradientu, aktualizujemy pozycje punktów na ścieżce w kierunku przeciwnym do gradientu. To wywołuje proces zejścia gradientowego, zmierzającego ku minimum funkcji celu.
Iteracje: Powtarzamy kroki 3-4 przez pewną liczbę iteracji lub do momentu, gdy zmiany w pozycjach punktów są wystarczająco małe.

10) Znane mikrokontrolery mające zastosowanie w robotyce inteligentnej, 
W dziedzinie robotyki inteligentnej wiele różnych mikrokontrolerów znajduje zastosowanie, zapewniając różne poziomy mocy obliczeniowej, efektywności energetycznej i wsparcia dla różnych funkcji. Oto kilka znanych mikrokontrolerów często używanych w robotyce inteligentnej:
Raspberry Pi: Chociaż Raspberry Pi to minikomputer, a nie mikrokontroler w tradycyjnym sensie, jest szeroko stosowany w projektach robotyki inteligentnej ze względu na swoją moc obliczeniową, możliwości interfejsu i wsparcie dla różnych interfejsów.
Arduino: Arduino to jedna z najpopularniejszych platform mikrokontrolerów, która jest powszechnie używana w projektach robotycznych. Jest dostępna w wielu wariantach, a ich otwarta natura przyciąga społeczność do tworzenia różnorodnych projektów.
STM32: Mikrokontrolery STM32 firmy STMicroelectronics są szeroko stosowane w robotyce ze względu na swoją wydajność, różnorodność modeli i bogate opcje komunikacyjne.
PIC Microcontroller: Produkowane przez Microchip, PIC (Peripheral Interface Controller) to popularne mikrokontrolery wśród hobbystów i profesjonalistów w dziedzinie robotyki.
BeagleBone: Podobnie jak Raspberry Pi, BeagleBone to minikomputer z wbudowanym mikrokontrolerem. Jest stosowany w projektach robotyki inteligentnej, oferując zaawansowane funkcje i interfejsy.
NVIDIA Jetson: Oferuje platformy z ukierunkowanymi na sztuczną inteligencję procesorami GPU, co czyni je idealnym wyborem dla projektów wymagających zaawansowanych algorytmów uczenia maszynowego i przetwarzania obrazu.
ESP32: Popularny mikrokontroler, szczególnie używany w projektach IoT i robotyce, charakteryzujący się niskim zużyciem energii, obsługą Wi-Fi i Bluetooth.
Atmel AVR: Mikrokontrolery AVR, takie jak te stosowane w platformach Arduino, są znane z łatwości użycia, dostępności i obsługi różnych projektów robotycznych.
Odroid: Kolejna rodzina minikomputerów, oferująca moc obliczeniową i interfejsy przydatne w projektach robotycznych.
Wybór mikrokontrolera zależy od konkretnych wymagań projektu, takich jak moc obliczeniowa, dostępność interfejsów komunikacyjnych, wielkość, koszt, a także specyficzne funkcje potrzebne do implementacji algorytmów sztucznej inteligencji czy kontroli ruchu.

11) Typy sensorów i ich możliwości – w kontekście Arduino Mega, 
Arduino Mega jest jedną z platform mikrokontrolerów Arduino, która oferuje szereg pinów wejścia/wyjścia, co umożliwia obsługę różnych typów sensorów. Poniżej znajduje się lista typów sensorów wraz z ich możliwościami, które mogą być używane w kontekście Arduino Mega:
Czujniki światła:
Fotorezystory: Mierzą natężenie światła, przydatne do detekcji zmian oświetlenia.
Czujniki światła:
Czujniki podczerwieni: Wykorzystywane do detekcji obiektów w zasięgu, np. czujniki ruchu PIR.
Czujniki dźwięku:
Mikrofony: Pozwalają na mierzenie poziomu dźwięku w otoczeniu.
Czujniki dźwięku: Umożliwiają detekcję określonych dźwięków lub hałasu.
Czujniki temperatury:
Termistory: Mierzą zmiany temperatury w otoczeniu.
Czujniki temperatury cyfrowe: Na przykład DS18B20, umożliwiający precyzyjne pomiar temperatury.
Czujniki wilgotności:
Czujniki wilgotności: Wykorzystywane do pomiaru wilgotności powietrza w otoczeniu.
Czujniki ruchu:
Akcelerometry: Mierzą przyspieszenie i pozycję.
Żyroskopy: Służą do pomiaru prędkości kątowej.
Magnetometry: Pomiar pola magnetycznego, przydatne w nawigacji.
Czujniki odległości:
Ultradźwiękowe czujniki odległości: Mierzą odległość na podstawie czasu odbicia fali ultradźwiękowej.
Czujniki podczerwieni odległości: Wykorzystują promieniowanie podczerwone do pomiaru odległości.
Czujniki gazów:
MQ Series Gas Sensors: Są w stanie wykryć różne gazy, takie jak metan czy CO2.
Czujniki biometryczne:
Czujniki odcisków palców: Umożliwiają identyfikację na podstawie odcisków palców.
Czujniki tętna: Wykorzystywane do pomiaru pulsu.
Czujniki obrazu:
Kamery wizyjne: Współpracujące z modułami kamery, umożliwiają analizę obrazów.

12) Metodologia tworzenia produktów data miningowych przez pryzmat systemów interakcji
Robot – Człowiek (Human – Robot interaction systems):
a) Kolejne etapy CRISP-DM
+ techniki preprocesowania danych:
- normalizacja,
 - standaryzacja,
 - dyskretyzacja,
 - zamiana na dummy variables,
 - techniki uzupełniania wartości nieznanych (missing values).
+ metody oceny jakości modeli:
- Trenuj i Testuj (Train and Test),
- Walidacja Krzyżowa Monte – Carlo (Monte Carlo Cross Validation),
- Walidacja Krzyżowa (Cross Validation),
- Walidacja Krzyżowa wewnętrzna (Internal Cross Validation),
- Wielokrotny Bootstrap,
- Leave One Out.
 + parametry szacowania jakości modeli:
 - dokładność globalna (Accuracy globalna),
 - dokładność zbalansowana (balanced accuracy),
 - precision,
 - recall,
 - Krzywa precision-recall,
 - Pokrycie (Coverage).
 + Przykłady wybranych technik klasyfikacji – ich idea,
+ Przykłady wybranych technik wzmacniania efektywności modeli, Random Forests,
Komitet Bootstrapów, AdaBoost,
+ Przykład formowania finalnego produktu Data Miningowego. 
Metodologia tworzenia produktów data miningowych przez pryzmat systemów interakcji Human – Robot:
a) Kolejne etapy CRISP-DM:
Zrozumienie Biznesowe (Business Understanding):
Zdefiniowanie celów biznesowych.
Określenie wymagań związanych z interakcją Human-Robot.
Zrozumienie danych (Data Understanding):
Zbieranie i analiza danych dotyczących interakcji Human-Robot.
Eksploracyjna analiza danych.
Przygotowanie danych (Data Preparation):
Normalizacja, standaryzacja, dyskretyzacja danych.
Konwersja na dummy variables.
Uzupełnianie brakujących danych.
Modelowanie (Modeling):
Wybór odpowiednich technik klasyfikacji (Random Forests, AdaBoost itp.).
Trenowanie modeli na danych treningowych.
Ewaluacja (Evaluation):
Ocena jakości modeli przy użyciu różnych metryk (dokładność, precision, recall, krzywa precision-recall itp.).
Wdrożenie (Deployment):
Implementacja modelu do systemu interakcji Human-Robot.
Monitorowanie i utrzymanie modelu w czasie rzeczywistym.
+ Techniki preprocesowania danych:
Normalizacja: Skalowanie wartości atrybutów do określonego zakresu.
Standaryzacja: Przydzielanie atrybutom wartości z przedziału średniej zero i odchylenia standardowego jeden.
Dyskretyzacja: Konwertowanie danych ciągłych na kategorie.
Zamiana na dummy variables: Przetwarzanie zmiennych kategorycznych na formę, którą może zrozumieć model.
Techniki uzupełniania wartości nieznanych (missing values): Wypełnianie brakujących danych, na przykład medianą, średnią itp.
+ Metody oceny jakości modeli:
Trenuj i Testuj (Train and Test): Podział danych na zbiór treningowy i testowy.
Walidacja Krzyżowa Monte-Carlo (Monte Carlo Cross Validation): Losowe podziały danych na zbiory treningowe i testowe.
Walidacja Krzyżowa (Cross Validation): Podział danych na k-krotnie i iteracyjne trenowanie i testowanie modelu.
Walidacja Krzyżowa Wewnętrzna (Internal Cross Validation): Podział danych na k-krotnie wewnątrz jednego zbioru treningowego.
Wielokrotny Bootstrap: Losowe próbkowanie z powtórzeniami danych treningowych.
Leave One Out: Każda obserwacja jest używana jako zbiór testowy dokładnie jeden raz.
+ Parametry szacowania jakości modeli:
Dokładność globalna (Accuracy globalna): Stosunek poprawnie sklasyfikowanych przypadków do wszystkich przypadków.
Dokładność zbalansowana (Balanced Accuracy): Uwzględniająca nierówności w rozkładzie klas.
Precision: Stosunek prawdziwie pozytywnych przypadków do wszystkich przewidzianych jako pozytywne.
Recall: Stosunek prawdziwie pozytywnych przypadków do wszystkich rzeczywistych pozytywnych przypadków.
Krzywa precision-recall: Graficzna reprezentacja precyzji w zależności od recall.
Pokrycie (Coverage): Procent przypadków, które zostały sklasyfikowane przez model.
+ Przykłady wybranych technik klasyfikacji:
Random Forests: Zestaw drzew decyzyjnych, które są szkolone niezależnie, a wyniki są łączone.
Komitet Bootstrapów: Tworzenie wielu modeli na podstawie różnych próbek bootstrapowych.
AdaBoost: Wzmacnianie ważności trudnych do sklasyfikowania przypadków poprzez iteracyjne modyfikowanie wag danych treningowych.
+ Przykłady wybranych technik wzmacniania efektywności modeli:
Random Forests: Zmniejsza overfitting i zwiększa dokładność przez kombinowanie wyników wielu drzew.
Komitet Bootstrapów: Poprawia stabilność i dokładność poprzez agregację wyników z różnych modeli.
AdaBoost: Poprawia dokładność poprzez przydzielanie większej wagi trudnym do sklasyfikowania przypadkom.
+ Przykład formowania finalnego produktu Data Miningowego:
Po przeprowadzeniu procesu CRISP-DM, wybieramy najlepszy model na podstawie oceny jakości.
Wdrażamy model w systemie interakcji Human-Robot.
Regularnie monitorujemy działanie modelu i dostosowujemy go do ewentualnych zmian w danych czy środowisku.
Ta metodologia obejmuje pełen cykl od zrozumienia biznesowego po wdrożenie, a wybór konkretnych technik zależy od specyfiki danych i wymagań biznesowych.